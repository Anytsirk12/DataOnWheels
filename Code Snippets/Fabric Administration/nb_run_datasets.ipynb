{"cells":[{"cell_type":"markdown","source":["## Pull in UDFs"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d0afd59c-faaf-4f4e-b692-cf474b0f54cc"},{"cell_type":"code","source":["%run nb_udfs\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[3,4,5,6,7,8,9,10,11,12,13],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.5271864Z","session_start_time":null,"execution_start_time":"2025-04-29T20:05:54.4517353Z","execution_finish_time":"2025-04-29T20:06:05.6012661Z","parent_msg_id":"430ca161-ee57-4ef1-8730-9c1fe19ff515"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 13, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e5570d46-c175-450a-ae4e-1de8a9e7fce5"},{"cell_type":"markdown","source":["## Run Datasets"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9c69a6e3-7356-4fc3-9b44-c4171c213ab0"},{"cell_type":"code","source":["workspace = 'Admin%20Center' #have to escape the & symbol and spaces\n","lakehouse = 'lh_monitoring'\n","\n","dataset_table = 'dimSemanticModels'\n","refreshHist_table = 'factRefreshHistory'\n","refreshSched_table = 'factRefreshSchedule'\n","source_table = 'factDatasetSources'\n","current_user = mssparkutils.env.getUserName()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.4270936Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:05.6032273Z","execution_finish_time":"2025-04-29T20:06:06.0064054Z","parent_msg_id":"12eee0ea-a360-4eaa-a10d-25afa02af92e"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"586d2905-dcfa-45b6-b8f1-b3b62b1224e2"},{"cell_type":"markdown","source":["### Dataset UDFs"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5c4d8164-3160-42b2-b337-86c068750afb"},{"cell_type":"code","source":["def get_data_sources(row):\n","    workspaceId = row['workspaceId']\n","    workspaceName = row['workspaceName']\n","    datasetId = row['id']\n","    try:\n","        response = fabric.get_tmsl(datasetId,workspaceId)\n","    except Exception as e:\n","        print(f'Failed api call: {e}')\n","        raise e\n","    tmsl_data = json.loads(response)\n","    # Extract top-level metadata\n","    dataset_id = tmsl_data.get(\"id\")\n","    created = tmsl_data.get(\"createdTimestamp\")\n","    last_update = tmsl_data.get(\"lastUpdate\")\n","    last_schema_update = tmsl_data.get(\"lastSchemaUpdate\")\n","\n","    # Prepare a list of rows\n","    rows = []\n","    for table in tmsl_data.get(\"model\", {}).get(\"tables\", []):\n","        table_name = table.get(\"name\")\n","        is_hidden = table.get(\"isHidden\")\n","        table_modified = table.get(\"modifiedTime\")\n","        table_struct_modified = table.get(\"structureModifiedTime\")\n","\n","        for partition in table.get(\"partitions\", []):\n","            partition_name = partition.get(\"name\")\n","            partition_mode = partition.get(\"mode\")\n","            partition_state = partition.get(\"state\")\n","            partition_modified = partition.get(\"modifiedTime\")\n","\n","            source = partition.get(\"source\", {})\n","            source_type = source.get(\"type\")\n","            source_expression = source.get(\"expression\")\n","\n","            # Append the flattened structure\n","            rows.append((\n","                dataset_id,\n","                created,\n","                last_update,\n","                last_schema_update,\n","                table_name,\n","                is_hidden,\n","                table_modified,\n","                table_struct_modified,\n","                partition_name,\n","                partition_mode,\n","                partition_state,\n","                partition_modified,\n","                source_type,\n","                source_expression\n","            ))\n","    # Define schema\n","    schema = StructType([\n","        StructField(\"dataset_id\", StringType(), True),\n","        StructField(\"createdTimestamp\", StringType(), True),\n","        StructField(\"lastUpdate\", StringType(), True),\n","        StructField(\"lastSchemaUpdate\", StringType(), True),\n","        StructField(\"table_name\", StringType(), True),\n","        StructField(\"table_isHidden\", BooleanType(), True),\n","        StructField(\"table_modifiedTime\", StringType(), True),\n","        StructField(\"table_structureModifiedTime\", StringType(), True),\n","        StructField(\"partition_name\", StringType(), True),\n","        StructField(\"partition_mode\", StringType(), True),\n","        StructField(\"partition_state\", StringType(), True),\n","        StructField(\"partition_modifiedTime\", StringType(), True),\n","        StructField(\"source_type\", StringType(), True),\n","        StructField(\"source_expression\", StringType(), True)\n","    ])\n","\n","    # Convert to DataFrame\n","    df_sources = spark.createDataFrame(rows,schema)\n","    df_sources = df_sources.withColumn(\"compositeKey\", concat(df_sources[\"datasetId\"], df_sources[\"partition_name\"]))\n","\n","    return df_sources\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.503482Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:06.0085936Z","execution_finish_time":"2025-04-29T20:06:06.5605844Z","parent_msg_id":"ff85fcc1-f081-41bb-8282-ab52011c6ec2"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ad3483f6-4330-429a-acac-8496db23f6aa"},{"cell_type":"code","source":["def get_refresh_history(row):\n","    workspaceId = row['workspaceId']\n","    workspaceName = row['workspaceName']\n","    datasetId = row['id']\n","    try:\n","        response = _base_api(\n","            request=f\"/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/refreshes\",\n","            method=\"get\"\n","        )\n","    except Exception as e:\n","        print(f'Failed api call: {e}')\n","        raise e\n","    \n","    json_data = response.json()\n","    if 'value' in json_data and isinstance(json_data['value'], list) and len(json_data['value']) > 0:\n","        df_pd = pd.json_normalize(json_data['value'])\n","        df_spark = spark.createDataFrame(df_pd).drop(\"refreshAttempts\")\n","        df_spark = df_spark.withColumn(\"datasetId\", lit(datasetId))\n","        return df_spark\n","    return None  # No refresh history"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.5651263Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:06.5627044Z","execution_finish_time":"2025-04-29T20:06:07.0918736Z","parent_msg_id":"ec4b7219-032c-4028-8316-22abf8477c2b"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 16, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"30ae0481-16f9-4228-afe1-19fc5f898e79"},{"cell_type":"code","source":["def get_refresh_schedule(row):\n","    workspaceId = row['workspaceId']\n","    workspaceName = row['workspaceName']\n","    datasetId = row['id']\n","\n","    try:\n","        response = _base_api(\n","            request=f\"/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/refreshSchedule\",\n","            method=\"get\"\n","        )\n","    except Exception as e:\n","        print(f'Failed api call: {e}')\n","        raise e\n","\n","    \n","    json_data = response.json()\n","\n","    if \"days\" in json_data and \"times\" in json_data and json_data[\"days\"] and json_data[\"times\"]:\n","        rows = [{\"day\": day, \"time\": time} for day in json_data[\"days\"] for time in json_data[\"times\"]]\n","        # Add metadata to each row\n","        for row in rows:\n","            row[\"enabled\"] = json_data[\"enabled\"]\n","            row[\"timeZone\"] = json_data[\"localTimeZoneId\"]\n","            row[\"notifyOption\"] = json_data[\"notifyOption\"]\n","        df_schedule = pd.DataFrame(rows)\n","        df_schedule_sp = spark.createDataFrame(df_schedule)\n","        df_schedule_sp = df_schedule_sp.withColumn(\"datasetId\", lit(datasetId))\n","        df_schedule_sp = df_schedule_sp.withColumn(\"compositeKey\", concat(df_schedule_sp[\"datasetId\"], df_schedule_sp[\"day\"], df_schedule_sp[\"time\"]))\n","        return df_schedule_sp\n","    return None  # No refresh schedule"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.606224Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:07.0938247Z","execution_finish_time":"2025-04-29T20:06:07.5488335Z","parent_msg_id":"002f5620-1070-4d7d-a8dd-1590cf954bd2"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 17, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e1b9817d-aaee-486a-b28f-c05553a96ad2"},{"cell_type":"code","source":["def process_dataset(row):\n","    workspaceId = row['workspaceId']\n","    workspaceName = row['workspaceName']\n","    datasetId = row['id']\n","    try:\n","        # Call both UDFs\n","        history_result = get_refresh_history(row)\n","        schedule_result = get_refresh_schedule(row)\n","        #sources_result = get_data_sources(row)\n","\n","        # Return both results in a dictionary or tuple\n","        return {\n","            \"datasetId\": datasetId,\n","            \"history\": history_result,\n","            \"schedule\": schedule_result\n","            #\"sources\": sources_result\n","        }\n","    except Exception as e:\n","        raise Exception(f\"Failed on dataset {datasetId} in workspace {workspaceName}: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":18,"statement_ids":[18],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.6526288Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:07.5508655Z","execution_finish_time":"2025-04-29T20:06:08.1185182Z","parent_msg_id":"96961f36-a22c-4087-ad90-9cafa4281c22"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 18, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"51bbba06-1547-4333-9951-02f6a73c8114"},{"cell_type":"code","source":["def union_hist():\n","    global df_refresh_hist\n","    if df_refresh_hist_list:\n","        df_refresh_hist = union_batches(df_refresh_hist_list, batch_size=50)\n","        # the line below is significantly slower than using the union_batches function\n","        #reduce(lambda a, b: a.unionByName(b, allowMissingColumns=True), df_refresh_hist_list)\n","        print(\"‚úÖ Refresh History dataframe ready\")\n","    else:\n","        print(\"‚ö†Ô∏è No refresh history found.\")\n","\n","def union_schedule():\n","    global df_refresh_schedule\n","    if df_refresh_schedule_list:\n","        df_refresh_schedule = union_batches(df_refresh_schedule_list, batch_size=50)\n","        print(\"‚úÖ Refresh Schedule dataframe ready\")\n","    else:\n","        print(\"‚ö†Ô∏è No refresh schedule found.\")\n","\n","def union_sources():\n","    global df_sources\n","    if df_sources_list:\n","        df_sources = union_batches(df_sources_list, batch_size=50)\n","        print(\"‚úÖ Data Sources dataframe ready\")\n","    else:\n","        print(\"‚ö†Ô∏è No sources found.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":19,"statement_ids":[19],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.702517Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:08.1207142Z","execution_finish_time":"2025-04-29T20:06:08.5396945Z","parent_msg_id":"682e45cd-8596-441b-8026-7b58197c1025"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 19, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d531896f-3b52-45b9-b273-147545f4e828"},{"cell_type":"code","source":["def load_history():\n","    refreshHistPath = udf_GetFilePath(workspace, lakehouse, refreshHist_table)\n","    #print(refreshHistPath)\n","    naturalKeyColumnList = ['id']\n","    primaryKeyColumnName = \"tableId\"\n","    returnValHist = udf_UpsertDimension(df_refresh_hist,1,refreshHistPath,naturalKeyColumnList,primaryKeyColumnName,False)\n","    print(returnValHist)\n","\n","def load_schedule():\n","    refreshSchedPath = udf_GetFilePath(workspace, lakehouse, refreshSched_table)\n","    #print(refreshSchedPath)\n","    naturalKeyColumnList = ['compositeKey']\n","    primaryKeyColumnName = \"tableId\"\n","    returnValSched = udf_UpsertDimension(df_refresh_schedule,1,refreshSchedPath,naturalKeyColumnList,primaryKeyColumnName,False)\n","    print(returnValSched)\n","\n","def load_sources():\n","    refreshSourcePath = udf_GetFilePath(workspace, lakehouse, source_table)\n","    #print(refreshSourcePath)\n","    naturalKeyColumnList = ['compositeKey']\n","    primaryKeyColumnName = \"tableId\"\n","    returnValSched = udf_UpsertDimension(df_sources,1,refreshSourcePath,naturalKeyColumnList,primaryKeyColumnName,False)\n","    print(returnValSched)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.7374346Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:08.5419614Z","execution_finish_time":"2025-04-29T20:06:09.0929908Z","parent_msg_id":"76a6c0cb-7a6e-4d5c-9358-48ce2488e253"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 20, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"902aaa6a-7775-47b1-8ff5-7c7b9fd34c12"},{"cell_type":"markdown","source":["### Load Dataset Tables"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"40a9d213-9e14-496f-bfb6-39d6b2a459cd"},{"cell_type":"code","source":["#get a list of all workspaces\n","response = fab_client.get(f\"/v1/admin/workspaces\")\n","df_workspaces = pd.json_normalize(response.json()['workspaces'])\n","#df_workspaces\n","df_workspaces = spark.createDataFrame(df_workspaces)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.7942305Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:09.0950606Z","execution_finish_time":"2025-04-29T20:06:11.6280969Z","parent_msg_id":"87567354-a351-4052-bc3f-d407bbbc64df"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 21, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3f9c0242-2b20-4ca9-b0a0-018a10a8c260"},{"cell_type":"code","source":["#get a list of all datasets and load to a table in the lakehouse\n","response = _base_api(\n","        request=f\"/v1.0/myorg/admin/datasets\",\n","        method=\"get\"\n","    )\n","df_datasets = pd.json_normalize(response.json()['value'])\n","df_datasets = spark.createDataFrame(df_datasets)\n","df_datasets = df_datasets.drop(\"queryScaleOutSettings.autoSyncReadOnlyReplicas\", \"queryScaleOutSettings.maxReadOnlyReplicas\",\"upstreamDatasets\",\"users\")\n","#df_datasets.printSchema()\n","#print(df_datasets.columns)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":22,"statement_ids":[22],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.8411416Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:11.6306615Z","execution_finish_time":"2025-04-29T20:06:15.2757497Z","parent_msg_id":"55c045b0-8ba7-47cf-b54a-1d10bacd9420"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 22, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c7db2c07-f212-4ef5-8473-45afd1d4a4ab"},{"cell_type":"code","source":["#creates a slowly changing dimension so we can keep an eye on any deleted datasets\n","datasetPath = udf_GetFilePath(workspace, lakehouse, dataset_table)\n","print(datasetPath)\n","naturalKeyColumnList = ['id']\n","primaryKeyColumnName = \"tableId\"\n","returnVal = udf_UpsertDimension(df_datasets,2,datasetPath,naturalKeyColumnList,primaryKeyColumnName,True)\n","print(returnVal)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":23,"statement_ids":[23],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.8804976Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:15.2782523Z","execution_finish_time":"2025-04-29T20:06:46.9842461Z","parent_msg_id":"2b6c6515-d3d5-4afb-af0d-04fa7374dc5a"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 23, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["abfss://b0e6b127-399e-40c0-8a07-6b50fce502ff@onelake.dfs.fabric.microsoft.com/e055fa9a-d676-4689-b18e-be950d62d16f/Tables/dimSemanticModels\n‚úÖ Upsert complete\n{'startTime': '2025-04-29 20:06:15.917552', 'stopTime': '2025-04-29 20:06:45.042898', 'details': '0 records updated, 1 records inserted from 7760 staging rows to abfss://b0e6b127-399e-40c0-8a07-6b50fce502ff@onelake.dfs.fabric.microsoft.com/e055fa9a-d676-4689-b18e-be950d62d16f/Tables/dimSemanticModels'}\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"080eec37-14ba-4888-b59b-ee7a3f081bfa"},{"cell_type":"code","source":["#creates a list of workspaces we want refresh history and schedules for\n","df_np_workspaces = df_workspaces \\\n","    .filter(df_workspaces[\"type\"] == \"Workspace\") \\\n","    .filter(df_workspaces[\"state\"] == \"Active\") \\\n","    .withColumnRenamed(\"id\",\"workspaceOgId\") \\\n","    .withColumnRenamed(\"name\",\"workspaceName\")\n","    #don't need refresh history/schedules for personal workspaces and not for the Admin Monitoring workspace\n","df_datasets_refreshable = df_datasets.filter(df_datasets[\"isRefreshable\"] ==1)\n","df_np_datasets = df_np_workspaces.join(df_datasets_refreshable, df_np_workspaces[\"workspaceOgId\"] == df_datasets_refreshable[\"workspaceId\"], how=\"inner\")\n","df_np_datasets = df_np_datasets.select(\"workspaceId\",\"workspaceName\",\"id\")\n","#df_np_datasets.head(5)\n","#df_dist_workspaces = df_np_datasets.select(\"workspaceName\",\"workspaceId\").distinct()\n","print(f'datasets: {df_np_datasets.count()}')\n","#df_dist_workspaces.show()\n","#df_dist_workspaces.count()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":24,"statement_ids":[24],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.9404527Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:46.9871905Z","execution_finish_time":"2025-04-29T20:06:48.0323409Z","parent_msg_id":"8331001c-b3c0-42bc-a69c-d2b5bc05e2c5"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 24, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["datasets: 3515\n"]}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"02d5bbfa-6cfc-42d2-98bc-1a86c3e39968"},{"cell_type":"code","source":["#### loop over datasets and get the refresh histories and schedules #### \n","# not using the admin capacity rest api because we want to grab all refresh histories that would impact the gateways for proper load balancing. \n","\n","# use this for only grabbing the refresh history for one workspace\n","# workspaceId = 'b0e6b127-399e-40c0-8a07-6b50fce502ff'\n","# df_np_datasets = df_np_datasets.filter(df_np_datasets[\"workspaceId\"] == workspaceId)\n","\n","\n","# Collect rows\n","rows = df_np_datasets.collect()\n","# This will hold all successful Spark DataFrames to union later\n","df_refresh_hist_list = []\n","df_refresh_schedule_list = []\n","df_sources_list = []\n","combined_results = []"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":25,"statement_ids":[25],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:49.9760325Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:48.0344644Z","execution_finish_time":"2025-04-29T20:06:49.3633794Z","parent_msg_id":"b77c36b7-0766-4b56-9202-8619fb89cc05"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 25, Finished, Available, Finished)"},"metadata":{}}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eb28e1b1-7664-4d33-88ca-6849bfc1369d"},{"cell_type":"code","source":["# Use thread pool to run API calls in parallel\n","# only runs 10 seconds faster to increase the max_workers to 30 from 10\n","with ThreadPoolExecutor(max_workers=10) as executor:\n","    # Submit each row (dataset) to the thread pool for processing\n","    # 'get_refresh_history' is the function each thread will run\n","    # 'future_to_row' maps each Future object back to the original row for error tracking\n","    future_to_row = {\n","        executor.submit(process_dataset, row): row for row in rows\n","    }\n","    # Iterate through each completed thread result as they finish (not in original order)\n","    for i, future in enumerate(as_completed(future_to_row), 1):\n","        try:\n","            # Get the result returned from the thread\n","            result = future.result()\n","            # If the function returned a non-null Spark DataFrame, add it to the list\n","            if result[\"history\"] is not None:\n","                df_refresh_hist_list.append(result[\"history\"])\n","            if result[\"schedule\"] is not None:\n","                df_refresh_schedule_list.append(result[\"schedule\"])  \n","            #if result[\"sources\"] is not None:\n","            #    df_sources_list.append(result[\"sources\"]) \n","        except Exception as e:\n","            # If the thread raised an exception, fetch the original row and report the error\n","            row = future_to_row[future]\n","            print(f\"‚ùå Failed for dataset {row['id']} in workspace {row['workspaceName']}: {e}\")\n","        # Print progress every 500 datasets processed\n","        if i % 500 == 0:\n","            print(f\"‚úÖ Processed {i} datasets...\")\n","            \n","# Once all threads are done, print a completion message\n","print('‚úÖ Looping complete!')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":26,"statement_ids":[26],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:05:50.0555391Z","session_start_time":null,"execution_start_time":"2025-04-29T20:06:49.3658727Z","execution_finish_time":"2025-04-29T20:11:19.8478314Z","parent_msg_id":"8563ead8-414d-44f0-a48a-16399374fc99"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 26, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Processed 500 datasets...\n‚úÖ Processed 1000 datasets...\n‚úÖ Processed 1500 datasets...\n‚úÖ Processed 2000 datasets...\n‚úÖ Processed 2500 datasets...\n‚úÖ Processed 3000 datasets...\n‚úÖ Processed 3500 datasets...\n‚úÖ Looping complete!\n"]}],"execution_count":14,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d7ac2711-811a-463e-897a-4beb3760ea6c"},{"cell_type":"code","source":["\n","# Union all non-empty DataFrames\n","df_refresh_hist = None\n","df_refresh_schedule = None\n","#df_sources = None\n","\n","# Run both unions in parallel\n","with ThreadPoolExecutor(max_workers=2) as executor:\n","    executor.submit(union_hist)\n","    executor.submit(union_schedule)\n","    #executor.submit(union_sources)\n","\n","#df_refresh_hist.show(5, truncate=False)\n","#df_refresh_schedule.show(5, truncate=False)\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":27,"statement_ids":[27],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:10:41.2773502Z","session_start_time":null,"execution_start_time":"2025-04-29T20:11:19.8499401Z","execution_finish_time":"2025-04-29T20:11:44.8171409Z","parent_msg_id":"59045960-ecae-4a64-ac4c-4030105c6b33"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 27, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Refresh History dataframe ready\n‚úÖ Refresh Schedule dataframe ready\n"]}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4baf7ee6-7ece-4cb0-8758-03ce1cbf48a2"},{"cell_type":"code","source":["# Run both loading into the lakehouse in parallel\n","with ThreadPoolExecutor(max_workers=2) as executor:\n","    executor.submit(load_history)\n","    executor.submit(load_schedule)\n","    #executor.submit(load_sources)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":28,"statement_ids":[28],"state":"finished","livy_statement_state":"available","session_id":"e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983","normalized_state":"finished","queued_time":"2025-04-29T20:10:44.4329348Z","session_start_time":null,"execution_start_time":"2025-04-29T20:11:44.8193635Z","execution_finish_time":"2025-04-29T20:16:07.1118813Z","parent_msg_id":"a3da2837-1490-44b5-a23e-e6f03d92f0d2"},"text/plain":"StatementMeta(, e2148dbf-e2bf-407c-a7cb-a3ea8e7dc983, 28, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üì¶ Initial load complete\n{'startTime': '2025-04-29 20:11:45.593370', 'stopTime': '2025-04-29 20:13:32.760945', 'details': '0 records updated, 11336 records inserted from 11336 staging rows to abfss://b0e6b127-399e-40c0-8a07-6b50fce502ff@onelake.dfs.fabric.microsoft.com/e055fa9a-d676-4689-b18e-be950d62d16f/Tables/factRefreshHistory'}\nüì¶ Initial load complete\n{'startTime': '2025-04-29 20:11:45.409592', 'stopTime': '2025-04-29 20:16:06.129288', 'details': '0 records updated, 18392 records inserted from 18392 staging rows to abfss://b0e6b127-399e-40c0-8a07-6b50fce502ff@onelake.dfs.fabric.microsoft.com/e055fa9a-d676-4689-b18e-be950d62d16f/Tables/factRefreshSchedule'}\n"]}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8c6263b3-ae87-4664-b3eb-701008509664"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}